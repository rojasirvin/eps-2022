data = wd,
vcov = ~st)
summary(modeloSA)
#Gráfico (iplot está incluido en fixest)
iplot(modeloSA)
modeloSA %>%
iplot(main = "fixest::sunab",
xlab = "Periodos desde el tratamiento",
ref.line = 1)
#Efecto de tratamiento
summary(modeloSA, agg = "ATT")
# You can also look at the total effect per cohort
summary(modeloSA, agg = "cohort")
wd <- wd %>%
mutate(periodos_desde_t = year-divyear)
View(wd)
View(wd)
table(wd$periodos_desde_t)
modeloSA <-  feols(suicide_rate ~ sunab(divyear, periodos_desde_t) | st + year,
data = filter(wd, periodos_desde_t>10),
vcov = ~st)
modeloSA <-  feols(suicide_rate ~ sunab(divyear, periodos_desde_t) | st + year,
data = filter(wd, periodos_desde_t>-10),
vcov = ~st)
summary(modeloSA)
#Gráfico (iplot está incluido en fixest)
iplot(modeloSA)
modeloSA %>%
iplot(main = "fixest::sunab",
xlab = "Periodos desde el tratamiento",
ref.line = 1)
#Efecto de tratamiento
summary(modeloSA, agg = "ATT")
#Agregado por cohortes
summary(modeloSA, agg = "cohort")
#DID
rm(list = ls())
options(scipen=999)
library(tidyverse)
library(janitor)
library(clubSandwich)
library(ExPanDaR) #for describing panel data
library(bacondecomp)
library(lfe)
library(fixest) #incluye el estimador de SA y el correspondiente gráfico de evento
#DID
rm(list = ls())
options(scipen=999)
library(tidyverse)
library(janitor)
library(clubSandwich)
library(ExPanDaR) #for describing panel data
library(bacondecomp)
library(lfe)
library(fixest) #incluye el estimador de SA y el correspondiente gráfico de evento
#Datos divorce contenidos en el paquete bacondecomp
wd <- divorce %>%
filter(year>1964 & year<1996 & sex==2) %>%
mutate(suicide_rate=suicide*1000000/(stpop*fshare),
year=as.numeric(year))
View(wd)
View(wd)
a <- select(wd, st, year, divyear, unilateral)
View(a)
View(a)
wd <- divorce %>%
filter(year>1964 & year<1996 & sex==2) %>%
mutate(suicide_rate=suicide*1000000/(stpop*fshare),
year=as.numeric(year))
#Esta es una de las funciones de ExPanDaR para explorar datos faltantes
prepare_missing_values_graph(wd, ts_id = "year")
#Esto genera una aplicación interactiva
ExPanD(df = wd,
ts_id="year",
cs_id="st",
title = "Wow, mis datos",
abstract = "Datos tomados de Stevenson & Wolfers (2006)")
?felm
modelo1 <- felm(suicide_rate ~ unilateral | factor(st) + factor(year),
data = wd)
summary(modelo1)
df_bacon <- bacon(suicide_rate ~ unilateral,
data = wd,
id_var = "st",
time_var = "year")
coef_bacon <- sum(df_bacon$estimate * df_bacon$weight)
print(paste("Weighted sum of decomposition =", round(coef_bacon, 4)))
#Replicamos la figura 6 en Goodman-Bacon (2021)
df_bacon %>%
ggplot(aes(x=weight,
y=estimate,
shape=type)) +
geom_point() +
geom_hline(yintercept = round(fit_tw$coefficients[2], 4))
fit_tw <- lm(suicide_rate ~ unilateral + factor(st) + factor(year),
data = wd)
print(paste("Two-way FE estimate =", round(fit_tw$coefficients[2], 4)))
#Replicamos la figura 6 en Goodman-Bacon (2021)
df_bacon %>%
ggplot(aes(x=weight,
y=estimate,
shape=type)) +
geom_point() +
geom_hline(yintercept = round(fit_tw$coefficients[2], 4))
View(df_bacon)
View(df_bacon)
?bacondecomp
??bacondecomp
blogdown:::preview_site()
xaringan::infinite_moon_reader()
?collapse
install.packages('formatR')
xaringan::infinite_moon_reader()
xaringan::infinite_moon_reader()
knitr::opts_chunk$set(collapse = TRUE)
library(tidyverse)
library(janitor)
library(sandwich) # Robust Covariance Matrix Estimators
library(clubSandwich)
library(modelsummary) #Summary Tables and Plots for Statistical Models and Data: Beautiful, Customizable, and Publication-Ready
library(lmtest) # Testing Linear Regression Models
library(car) #Companion to Applied Regression
library(COUNT)
library(AER)
library(stargazer)
data.morocco<- read.csv("./crepon_morocco_analysis.csv") %>%
select(treatment,client,expense_total )
knitr::opts_chunk$set(collapse = TRUE)
library(tidyverse)
library(janitor)
library(sandwich) # Robust Covariance Matrix Estimators
library(clubSandwich)
library(modelsummary) #Summary Tables and Plots for Statistical Models and Data: Beautiful, Customizable, and Publication-Ready
library(lmtest) # Testing Linear Regression Models
library(car) #Companion to Applied Regression
library(COUNT)
library(AER)
library(stargazer)
data.morocco<-read_csv("./crepon_morocco_balance.csv",
locale = locale(encoding = "latin1")) %>%
clean_names() %>%
filter(merge_indicator!=1)
data.morocco %>%
group_by(treatment) %>%
summarize(mean=mean(members_resid_bl),
std=sd(members_resid_bl), n=n()) %>%
ungroup()
dif_members <- lm(members_resid_bl ~ treatment + factor(paire),
data=data.morocco)
summary(dif_members)$coef[1:7,]
nobs(dif_members)
coef_test(dif_members,
vcov = "CR1S",
cluster = data.morocco$demi_paire)[1:2,]
##Pero hay selección, veamos un tabulado cruzado
data.morocco %>%
mutate(treatment=factor(treatment, levels=c(0,1),labels=c("Control", "Tratamiento"))) %>%
mutate(client=factor(client, levels=c(0,1),labels=c("No cliente", "Cliente"))) %>%
tabyl(treatment, client)
#Para el número de miembros del hogar
dif_members_client <- lm(members_resid_bl ~ client + factor(paire),
data=data.morocco)
coef_test(dif_members_client,
vcov = "CR1S",
cluster = data.morocco$demi_paire)[1:2,]
#Para el número de actividades económicas del hogar
dif_activities_client <- lm(act_number_bl ~ client + factor(paire),
data=data.morocco)
coef_test(dif_activities_client,
vcov = "CR1S",
cluster = data.morocco$demi_paire)[1:2,]
data.morocco<-read_csv("./crepon_morocco_analysis.csv")   %>%
clean_names()
res_fr<- lm(expense_total ~ treatment +
members_resid_bl + nadults_resid_bl +
head_age_bl + act_livestock_bl + act_business_bl +
borrowed_total_bl + members_resid_d_bl +
nadults_resid_d_bl + head_age_d_bl + act_livestock_d_bl +
act_business_d_bl + borrowed_total_d_bl +
ccm_resp_activ + other_resp_activ + ccm_resp_activ_d +
other_resp_activ_d + factor(paire),
data=data.morocco)
coef_test(res_fr,
vcov = "CR1S",
cluster = data.morocco$demi_paire)[1:2,]
res_fs<- lm(client ~ treatment +
members_resid_bl + nadults_resid_bl +
head_age_bl + act_livestock_bl + act_business_bl +
borrowed_total_bl + members_resid_d_bl +
nadults_resid_d_bl + head_age_d_bl + act_livestock_d_bl +
act_business_d_bl + borrowed_total_d_bl +
ccm_resp_activ + other_resp_activ + ccm_resp_activ_d +
other_resp_activ_d + factor(paire),
data=data.morocco)
coef_test(res_fs,
vcov = "CR1S",
cluster = data.morocco$demi_paire)[1:2,]
res_mco <- lm(expense_total ~ client +
members_resid_bl + nadults_resid_bl +
head_age_bl + act_livestock_bl + act_business_bl +
borrowed_total_bl + members_resid_d_bl +
nadults_resid_d_bl + head_age_d_bl + act_livestock_d_bl +
act_business_d_bl + borrowed_total_d_bl +
ccm_resp_activ + other_resp_activ + ccm_resp_activ_d +
other_resp_activ_d + factor(paire),
data=filter(data.morocco,treatment==1))
coef_test(res_mco,
vcov = "CR1S",
cluster =filter(data.morocco,treatment==1)$demi_paire)[1:2,]
#Columna 3, Panel B, Tabla 9. LATE:
res_iv <- ivreg(expense_total ~ client + members_resid_bl + nadults_resid_bl
+ head_age_bl + act_livestock_bl + act_business_bl
+ borrowed_total_bl + members_resid_d_bl + nadults_resid_d_bl
+ head_age_d_bl + act_livestock_d_bl + act_business_d_bl
+ borrowed_total_d_bl + ccm_resp_activ + other_resp_activ
+ ccm_resp_activ_d  + other_resp_activ_d + factor(paire) |
treatment +  members_resid_bl + nadults_resid_bl
+ head_age_bl + act_livestock_bl + act_business_bl
+ borrowed_total_bl + members_resid_d_bl + nadults_resid_d_bl
+ head_age_d_bl + act_livestock_d_bl + act_business_d_bl
+ borrowed_total_d_bl + ccm_resp_activ + other_resp_activ
+ ccm_resp_activ_d  + other_resp_activ_d + factor(paire),
data=data.morocco)
summary(res_iv)$coefficients[1:2,]
#Errores agrupados a nivel pareja (paire)
coef_test(res_iv,
vcov = "CR1S",
cluster = data.morocco$demi_paire)[1:2,]
data.morocco<-read_csv("./crepon_morocco_analysis.csv")   %>%
clean_names()
mean_cliente<-data.morocco %>%
group_by(treatment) %>%
summarize(p_cliente=mean(client, na.rm=F)) %>%
ungroup()
mean_gasto<-data.morocco %>%
group_by(treatment) %>%
summarize(m_gasto=mean(expense_total, na.rm=F)) %>%
ungroup()
#Neceistamos la diferencia de gastos y de probabilidad de ser cliente
dif_gasto <- mean_gasto[2,2]-mean_gasto[1,2]
dif_cliente <- mean_cliente[2,2]-mean_cliente[1,2]
Wald <- as.numeric(dif_gasto / dif_cliente)
Wald
Wald_vi <- ivreg(expense_total ~ client  | treatment,
data=data.morocco)
#Notemos que obtenemos directamente el error estándar
summary(Wald_vi)
data.morocco<- read.csv("./crepon_morocco_analysis.csv") %>%
select(treatment,client,expense_total )
data.morocco<- read.csv("./crepon_morocco_analysis.csv")
View(data.morocco)
View(data.morocco)
data.morocco<- read.csv("./crepon_morocco_analysis.csv") %>%
select(treatment,client,expense_total )
?select
data.morocco<- read.csv("./crepon_morocco_analysis.csv") %>%
select(treatment,client,expense_total)
data.morocco<- read.csv("./crepon_morocco_analysis.csv") %>%
clean_names() %>%
select(treatment,client,expense_total)
xaringan::infinite_moon_reader()
xaringan::infinite_moon_reader()
??ivreg
xaringan::infinite_moon_reader()
xaringan::infinite_moon_reader()
??setorder
knitr::opts_chunk$set(collapse = TRUE)
library(tidyverse)
library(janitor)
library(sandwich) # Robust Covariance Matrix Estimators
library(clubSandwich)
library(modelsummary) #Summary Tables and Plots for Statistical Models and Data: Beautiful, Customizable, and Publication-Ready
library(lmtest) # Testing Linear Regression Models
library(AER)
data.pvalues<-read_csv("./pvalues.csv",
locale = locale(encoding = "latin1"))
alpha <- 0.05
#Corrección con familias originales
#Ordenar de menor a mayor por familia
data.fam.or <- data.pvalues %>%
sort(data.fam.or,familia,p) #usé setorder de la libreria data.table
View(data.pvalues)
View(data.pvalues)
data.fam.or <- data.pvalues %>%
sort(familia,p)
data.fam.or <- data.pvalues %>%
sort(familia,p)
?sort
data.pvalues<-read_csv("./pvalues.csv",
locale = locale(encoding = "latin1"))
alpha <- 0.05
#Corrección con familias originales
#Ordenar de menor a mayor por familia
data.fam.or <- data.pvalues %>%
sort(familia,p)
?arrange
data.fam.or <- data.pvalues %>%
arrange(familia,p)
View(data.fam.or)
View(data.fam.or)
#Número de posición
data.fam.or <- data.fam.or %>%
group_by(familia) %>%
mutate(posicion=seq(along.with = familia)) %>%
mutate(numerohipotesis=max(posicion)) %>%
ungroup()
data.pvalues<-read_csv("./pvalues.csv",
locale = locale(encoding = "latin1"))
alpha <- 0.05
#Corrección con familias originales
#Ordenar de menor a mayor por familia
data.fam.or <- data.pvalues %>%
arrange(familia,p)
#Número de posición
data.fam.or <- data.fam.or %>%
group_by(familia) %>%
mutate(posicion=seq(along.with = familia)) %>%
mutate(numerohipotesis=max(posicion)) %>%
ungroup()
#Reglas (1 = rechazar H0, 0 = no rechazar)
data.fam.or <- data.fam.or %>%
mutate(regla_sincorr=ifelse(p<.05,1,0)) %>%
mutate(alpha_bonferroni=alpha/numerohipotesis) %>%
mutate(corrector_bh=posicion/numerohipotesis) %>%
mutate(q=corrector_bh*alpha) %>%
mutate(regla_bonferroni=ifelse(p<alpha_bonferroni,1,0)) %>%
mutate(regla_bh=ifelse(p<q,1,0))
data.fam.or <- data.fam.or %>%
arrange(hipotesis)
data.fam.or %>%
select(hipotesis,familia,regla_sincorr,regla_bonferroni,regla_bh)
View(data.fam.or)
View(data.fam.or)
#Ahora familias es la familia corregida
data.fam.corr <- data.pvalues %>%
arrange(familia_corregida,p)
#Número de posición
data.fam.corr <- data.fam.corr %>%
group_by(familia_corregida) %>%
mutate(posicion=seq(along.with = familia_corregida)) %>%
mutate(numerohipotesis=max(posicion)) %>%
ungroup()
#Reglas (1 = rechazar H0, 0 = no rechazar)
data.fam.corr <- data.fam.corr %>%
mutate(regla_sincorr=ifelse(p<.05,1,0)) %>%
mutate(alpha_bonferroni=alpha/numerohipotesis) %>%
mutate(corrector_bh=posicion/numerohipotesis) %>%
mutate(q=corrector_bh*alpha) %>%
mutate(regla_bonferroni=ifelse(p<alpha_bonferroni,1,0)) %>%
mutate(regla_bh=ifelse(p<q,1,0))
data.fam.corr <- data.fam.corr %>%
arrange(hipotesis)
data.fam.corr %>%
select(hipotesis,familia_corregida,regla_sincorr,regla_bonferroni,regla_bh)
xaringan::infinite_moon_reader()
blogdown::build_site()
blogdown:::preview_site()
blogdown:::preview_site()
blogdown::build_site()
blogdown::stop_server()
blogdown::stop_server()
blogdown::build_site()
blogdown:::preview_site()
blogdown::stop_server()
blogdown::build_site()
blogdown:::preview_site()
blogdown::stop_server()
blogdown::build_site()
blogdown:::preview_site()
blogdown::build_site()
blogdown::stop_server()
blogdown::build_site()
blogdown::stop_server()
blogdown::build_site()
blogdown:::preview_site()
blogdown::stop_server()
blogdown::build_site()
blogdown:::preview_site()
blogdown::stop_server()
blogdown::build_site()
blogdown:::preview_site()
blogdown::stop_server()
blogdown:::preview_site()
blogdown::build_site()
blogdown::stop_server()
blogdown:::preview_site()
?blogdown
blogdown:::preview_site()
blogdown::stop_server()
blogdown:::preview_site()
install.packages('knitr')
install.packages("knitr")
blogdown:::preview_site()
update.packages('rmarkdown')
update.packages('rmarkdown')
install.packages('rmarkdown')
install.packages("rmarkdown")
blogdown:::preview_site()
install.packages("rlang")
knitr::opts_chunk$set(echo = T, warning = F, message = F)
library(tidyverse)
library(janitor)
library(clubSandwich)
library(MatchIt)
library(Zelig)
devtools::install_github('IQSS/Zelig')
knitr::opts_chunk$set(echo = T, warning = F, message = F)
library(tidyverse)
library(janitor)
library(clubSandwich)
library(MatchIt)
library(Zelig)
data.smoking<-read_csv(
"./cattaneo_smoking.csv",
locale = locale(encoding = "latin1")) %>%
clean_names() %>%
mutate(smoke=ifelse(mbsmoke=="smoker",1,0)) %>%
mutate(married=ifelse(mmarried=="married",1,0)) %>%
mutate(firstbaby=ifelse(fbaby=="Yes",1,0))
#Asegurarse que no hay NA, matchit no acepta NA
data.smoking <- data.smoking[complete.cases(data.smoking), ]
#Una semilla para todo el trabajo
set.seed(1021)
library(modelsummary)
datasummary_balance(~smoking,
fmt = "%.2f",
data = data.smoking,
title = "Pruebas de balance",
notes = "Fuente: Cattaneo (2009)")
datasummary_balance(~smoke,
fmt = "%.2f",
data = data.smoking,
title = "Pruebas de balance",
notes = "Fuente: Cattaneo (2009)")
datasummary_balance(~smoke,
fmt = "%.2f",
data = data.smoking,
title = "Pruebas de balance",
notes = "Fuente: Cattaneo (2009)")
binaria <- "smoke"
variables <- c("married", "firstbaby", "medu", "nprenatal", "foreign", "mhisp", "fage")
ps <- as.formula(paste(binaria,
paste(variables,
collapse ="+"),
sep= " ~ "))
print(ps)
binaria <- "smoke"
variables <- c("married", "firstbaby", "medu", "nprenatal", "foreign", "mhisp", "fage", "alcohol")
ps <- as.formula(paste(binaria,
paste(variables,
collapse ="+"),
sep= " ~ "))
print(ps)
m.out <- matchit(formula=ps,
method = "nearest",
ratio = 1,
distance= "logit",
replace = FALSE,
data = data.smoking)
summary(m.out)
plot(m.out, type = "jitter")
plot(m.out, type = "hist")
m.data <- match.data(m.out)
#Esta matriz nos dice quién es el match de quién
head(m.out$match.matrix)
z.out <- zelig(bweight~smoke,
data = m.data,
model = "ls")
z.out
binaria <- "smoke"
variables <- c("married", "firstbaby", "medu", "nprenatal", "foreign", "mhisp", "fage")
ps <- as.formula(paste(binaria,
paste(variables,
collapse ="+"),
sep= " ~ "))
print(ps)
m.out <- matchit(formula=ps,
method = "nearest",
ratio = 1,
distance= "logit",
replace = FALSE,
data = data.smoking)
summary(m.out)
plot(m.out, type = "jitter")
plot(m.out, type = "hist")
m.data <- match.data(m.out)
#Esta matriz nos dice quién es el match de quién
head(m.out$match.matrix)
z.out <- zelig(bweight~smoke,
data = m.data,
model = "ls")
z.out
#Creamos dos objetos con las dos situaciones que queremos simular
x.out <- setx(z.out, smoke=0)
x1.out <- setx1(z.out, smoke=1)
#Corremos la simulación
sim.out <- sim(z.out, x=x.out, x1=x1.out)
summary(sim.out)
z.out <- zelig(bweight~smoke+distance+married+firstbaby+medu+nprenatal+foreign+mhisp+fage,
data = m.data,
model = "ls")
z.out
z.out <- zelig(bweight~smoke+distance+married+firstbaby+medu+nprenatal+foreign+mhisp+fage,
data = m.data,
model = "ls")
z.out
#Creamos dos objetos con las dos situaciones que queremos simular
x.out <- setx(z.out, smoke=0)
x1.out <- setx1(z.out, smoke=1)
#Corremos la simulación
sim.out <- sim(z.out, x=x.out, x1=x1.out)
summary(sim.out)
