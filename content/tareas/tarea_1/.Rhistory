statistic = "std.error",
estimate = "coef (std.error)",
coef_map = c('hopegroup' = "Hope Group"),
coef_omit = "Intercept",
gof_omit = 'DF|Deviance|R2|AIC|BIC',
stars=c('*' = .1, '**' = .05, '***'=0.01),
vcov = NULL)
#Todo en una tabla
modelsummary::modelsummary(models,
statistic = "std.error",
estimate = "estimate",
coef_map = c('hopegroup' = "Hope Group"),
coef_omit = "Intercept",
gof_omit = 'DF|Deviance|R2|AIC|BIC',
stars=c('*' = .1, '**' = .05, '***'=0.01),
vcov = NULL)
modelsummary::modelsummary(models,
statistic = "std.error",
estimate = "estimate",
coef_omit = "Intercept",
gof_omit = 'DF|Deviance|R2|AIC|BIC',
stars=c('*' = .1, '**' = .05, '***'=0.01),
vcov = NULL)
#Todo en una tabla
modelsummary::modelsummary(models,
statistic = "std.error",
estimate = "{estimate} ({std.error}){stars}",
coef_omit = "Intercept",
gof_omit = 'DF|Deviance|R2|AIC|BIC',
stars=c('*' = .1, '**' = .05, '***'=0.01),
vcov = NULL)
modelsummary::modelsummary(models,
statistic = "std.error",
coef_map = c('hopegroup' = "Hope Group"),
coef_omit = "Intercept",
gof_omit = 'DF|Deviance|R2|AIC|BIC',
stars=c('*' = .1, '**' = .05, '***'=0.01),
notes = NULL)
summary(e1 <- lm_robust(StdAnderAgencyIndex ~ hopegroup + age + educ + evangelical + children + children_under_18 + bankleader + Dwelling_Index,
clusters = communitybank,
se_type = "CR0",
data = filter(data, t==2)))
#Agregar las parejas
summary(e2 <- lm_robust(StdAnderAgencyIndex ~ hopegroup + age + educ + evangelical + children + children_under_18 + bankleader + Dwelling_Index +
factor(pair_number),
clusters = communitybank,
se_type = "CR0",
data = filter(data, t==2)))
#2. Estimación de efectos de tratamiento
summary(e1 <- lm_robust(StdAnderAgencyIndex ~ hopegroup + age + educ + evangelical + children + children_under_18 + bankleader + Dwelling_Index,
clusters = communitybank,
se_type = "CR0",
data = filter(data, t==2)))
#Agregar las parejas
summary(e2 <- lm_robust(StdAnderAgencyIndex ~ hopegroup + age + educ + evangelical + children + children_under_18 + bankleader + Dwelling_Index +
factor(pair_number),
clusters = communitybank,
se_type = "CR0",
data = filter(data, t==2)))
modelsummary::modelsummary(e1, e2,
statistic = "std.error",
coef_map = c('hopegroup' = "Hope Group"),
coef_omit = "Intercept",
gof_omit = 'DF|Deviance|R2|AIC|BIC',
stars=c('*' = .1, '**' = .05, '***'=0.01))
#Todo en una tabla
modelsummary::modelsummary(models,
gof_omit = 'DF|Deviance|R2|AIC|BIC',
stars=c('*' = .1, '**' = .05, '***'=0.01))
modelsummary::modelsummary(e1, e2,
statistic = "std.error",
gof_omit = 'DF|Deviance|R2|AIC|BIC',
stars=c('*' = .1, '**' = .05, '***'=0.01))
modelsummary::modelsummary(list(e1, e2),
statistic = "std.error",
coef_map = c('hopegroup' = "Hope Group"),
coef_omit = "Intercept",
gof_omit = 'DF|Deviance|R2|AIC|BIC',
stars=c('*' = .1, '**' = .05, '***'=0.01))
#2. Estimación de efectos de tratamiento
summary(e0 <- lm_robust(StdAnderAgencyIndex ~ hopegroup,
se_type = "HC1",
data = filter(data, t==2)))
summary(e0 <- lm_robust(StdAnderAgencyIndex ~ hopegroup,
se_type = "HC1",
data = filter(data, t==2)))
#Errores agrupados
summary(e1 <- lm_robust(StdAnderAgencyIndex ~ hopegroup + age + educ + evangelical + children + children_under_18 + bankleader + Dwelling_Index,
clusters = communitybank,
se_type = "CR0",
data = filter(data, t==2)))
#Agregar las parejas
summary(e2 <- lm_robust(StdAnderAgencyIndex ~ hopegroup + age + educ + evangelical + children + children_under_18 + bankleader + Dwelling_Index +
factor(pair_number),
clusters = communitybank,
se_type = "CR0",
data = filter(data, t==2)))
modelsummary::modelsummary(list(e0, e1, e2),
statistic = "std.error",
coef_map = c('hopegroup' = "Hope Group"),
coef_omit = "Intercept",
gof_omit = 'DF|Deviance|R2|AIC|BIC',
stars=c('*' = .1, '**' = .05, '***'=0.01))
summary(e0 <- lm_robust(StdAnderAgencyIndex ~ hopegroup + age + educ + evangelical + children + children_under_18 + bankleader + Dwelling_Index,
se_type = "HC1",
data = filter(data, t==2)))
#2. Estimación de efectos de tratamiento
#Solo errores robustos
summary(e0a <- lm_robust(StdAnderAgencyIndex ~ hopegroup,
se_type = "HC1",
data = filter(data, t==2)))
#Agregamos controles
summary(e0b <- lm_robust(StdAnderAgencyIndex ~ hopegroup + age + educ + evangelical + children + children_under_18 + bankleader + Dwelling_Index,
se_type = "HC1",
data = filter(data, t==2)))
#Errores agrupados
summary(e1 <- lm_robust(StdAnderAgencyIndex ~ hopegroup + age + educ + evangelical + children + children_under_18 + bankleader + Dwelling_Index,
clusters = communitybank,
se_type = "CR0",
data = filter(data, t==2)))
#Agregar indicadoras de parejas
summary(e2 <- lm_robust(StdAnderAgencyIndex ~ hopegroup + age + educ + evangelical + children + children_under_18 + bankleader + Dwelling_Index +
factor(pair_number),
clusters = communitybank,
se_type = "CR0",
data = filter(data, t==2)))
modelsummary::modelsummary(list(e0, e1, e2),
statistic = "std.error",
coef_map = c('hopegroup' = "Hope Group"),
coef_omit = "Intercept",
gof_omit = 'DF|Deviance|R2|AIC|BIC',
stars=c('*' = .1, '**' = .05, '***'=0.01))
modelsummary::modelsummary(list(e0a, e0b, e1, e2),
statistic = "std.error",
coef_map = c('hopegroup' = "Hope Group"),
coef_omit = "Intercept",
gof_omit = 'DF|Deviance|R2|AIC|BIC',
stars=c('*' = .1, '**' = .05, '***'=0.01))
#3. ANCOVA
#Agregar el valor de y en la línea base y un indicador para valores faltantes
summary(e3 <- lm_robust(StdAnderAgencyIndex ~ hopegroup + age + educ + evangelical + children + children_under_18 + bankleader + Dwelling_Index +
factor(pair_number) +
Baseline_StdAnderAgencyIndex +
M_Baseline_StdAnderAgencyIndex,
clusters = communitybank,
se_type = "CR0",
data = filter(data, t==2)))
modelsummary::modelsummary(list(e0a, e0b, e1, e2, e3),
statistic = "std.error",
coef_map = c('hopegroup' = "Hope Group"),
coef_omit = "Intercept",
gof_omit = 'DF|Deviance|R2|AIC|BIC',
stars=c('*' = .1, '**' = .05, '***'=0.01))
summary(epaper <- lm_robust(StdAnderAgencyIndex ~ hopegroup:followup1 + hopegroup:followup2 + followup2 +
age + educ + evangelical + children + children_under_18 + bankleader + Dwelling_Index +
factor(pair_number) +
Baseline_StdAnderAgencyIndex +
M_Baseline_StdAnderAgencyIndex,
clusters = communitybank,
se_type = "stata",
data = filter(data,t!=0)))
#Usamos los datos de la ronda de seguimiento de 1 mes y la ronda final al mismo tiempo
summary(epaper <- lm_robust(StdAnderAgencyIndex ~ hopegroup:followup1 + hopegroup:followup2 + followup2 +
age + educ + evangelical + children + children_under_18 + bankleader + Dwelling_Index +
factor(pair_number) + factor(type_of_business)
Baseline_StdAnderAgencyIndex +
M_Baseline_StdAnderAgencyIndex,
clusters = communitybank,
se_type = "stata",
data = filter(data,t!=0)))
#Usamos los datos de la ronda de seguimiento de 1 mes y la ronda final al mismo tiempo
summary(epaper <- lm_robust(StdAnderAgencyIndex ~ hopegroup:followup1 + hopegroup:followup2 + followup2 +
age + educ + evangelical + children + children_under_18 + bankleader + Dwelling_Index +
factor(pair_number) + factor(type_of_business) +
Baseline_StdAnderAgencyIndex +
M_Baseline_StdAnderAgencyIndex,
clusters = communitybank,
se_type = "stata",
data = filter(data,t!=0)))
modelsummary::modelsummary(list('robustos'=e0a, e0b, e1, e2),
statistic = "std.error",
coef_map = c('hopegroup' = "Hope Group"),
coef_omit = "Intercept",
gof_omit = 'DF|Deviance|R2|AIC|BIC',
stars=c('*' = .1, '**' = .05, '***'=0.01))
modelsummary::modelsummary(list('Errores Robustos'=e0a,
'Errores Robustos + X'=e0b,
'Errores agrupados'=e1,
'Con parejas'=e2),
statistic = "std.error",
coef_map = c('hopegroup' = "Hope Group"),
coef_omit = "Intercept",
gof_omit = 'DF|Deviance|R2|AIC|BIC',
stars=c('*' = .1, '**' = .05, '***'=0.01))
modelsummary::modelsummary(list('Errores Robustos'=e0a,
'Errores Robustos + X'=e0b,
'Errores agrupados + X'=e1,
'Errores agrupados + X + parejas'=e2),
statistic = "std.error",
coef_map = c('hopegroup' = "Hope Group"),
coef_omit = "Intercept",
gof_omit = 'DF|Deviance|R2|AIC|BIC',
stars=c('*' = .1, '**' = .05, '***'=0.01))
modelsummary::modelsummary(list('Errores Robustos'=e0a,
'Errores Robustos + X'=e0b,
'Errores agrupados + X'=e1,
'Errores agrupados + X + parejas'=e2,
'+ ANCOVA'=e3),
statistic = "std.error",
coef_map = c('hopegroup' = "Hope Group"),
coef_omit = "Intercept",
gof_omit = 'DF|Deviance|R2|AIC|BIC',
stars=c('*' = .1, '**' = .05, '***'=0.01))
modelsummary::modelsummary(list('Errores Robustos'=e0a,
'Errores Robustos + X'=e0b,
'Errores agrupados + X'=e1,
'Errores agrupados + X + parejas'=e2),
statistic = "std.error",
coef_map = c('hopegroup' = "Hope Group"),
coef_omit = "Intercept",
gof_omit = 'DF|Deviance|R2|AIC|BIC',
stars=c('*' = .1, '**' = .05, '***'=0.01),
title = "Efectos de tratamiento en índice de agencia 12 meses después de la intervención")
modelsummary::modelsummary(list('Errores Robustos'=e0a,
'Errores Robustos + X'=e0b,
'Errores agrupados + X'=e1,
'Errores agrupados + X + parejas'=e2,
'+ ANCOVA'=e3),
statistic = "std.error",
coef_map = c('hopegroup' = "Hope Group"),
coef_omit = "Intercept",
gof_omit = 'DF|Deviance|R2|AIC|BIC',
stars=c('*' = .1, '**' = .05, '***'=0.01),
title = "Efectos de tratamiento en el índice de agencia 12 meses después de la intervención")
# Espacio de trabajo ----
rm(list = ls())
options(scipen=999) # Prevenir notación científica
library(tidyverse)
rm(list = ls())
options(scipen=999)
library(tidyverse)
ESAA_Puebla_MX = haven::read_sav("ESAA_Puebla_MX.SAV")
ESAA_Puebla_MX = haven::read_sav("C:/Users/rojas/Dropbox/seguridad_alimentaria/ESAA_Puebla_MX.SAV")
View(ESAA_Puebla_MX)
View(ESAA_Puebla_MX)
write.csv(ESAA_Puebla_MX, "C:/Users/rojas/Dropbox/seguridad_alimentaria/ESAA_Puebla_MX.csv")
write.csv(ESAA_Puebla_MX,
"C:/Users/rojas/Dropbox/seguridad_alimentaria/ESAA_Puebla_MX.csv",
row.names = F)
ESAA_Tabasco_MX = haven::read_sav("C:/Users/rojas/Dropbox/seguridad_alimentaria/ESAA_Tabasco_MX.SAV")
write.csv(ESAA_Tabasco_MX,
"C:/Users/rojas/Dropbox/seguridad_alimentaria/ESAA_Tabasco_MX.csv",
row.names = F)
# Espacio de trabajo ----
rm(list = ls())
options(scipen=999) # Prevenir notación científica
library(tidyverse)
library(janitor)
library(sandwich)
library(readr)
library(sandwich)
library(clubSandwich)
library(modelsummary)
library(estimatr)
library(stargazer)
library(lfe)
##Augmented SC----
#devtools::install_github("ebenmichael/augsynth")
library(augsynth)
data(kansas)
kansas %>%
select(year, qtr, year_qtr, state, treated, gdp, lngdpcapita) %>%
filter(state == "Kansas" & year_qtr >= 2012 & year_qtr < 2013)
syn <- augsynth(lngdpcapita ~ treated,
unit = fips,
time = year_qtr,
data = kansas,
progfunc = "None",
scm = T)
summary(syn)
#Do a graph
dp <- kansas %>%
filter(state=="Kansas") %>%
select(year_qtr, lngdpcapita) %>%
mutate(ys=predict(syn)) %>%
rename(y=lngdpcapita) %>%
mutate(gap=y-ys)
dp %>%
ggplot()+
geom_line(aes(y=y,x=year_qtr)) +
geom_line(aes(y=ys,x=year_qtr), linetype = "dashed")+
ylab("Per capita GDP")+
xlab("year/qtr")+
geom_vline(xintercept=2012.50, color = "black", size=1, linetype="dashed")
View(kansas)
View(kansas)
kansas %>%
select(year, qtr, year_qtr, state, treated, gdp, lngdpcapita) %>%
filter(state == "Kansas" & year_qtr >= 2012 & year_qtr < 2013)
summary(syn)
dp <- kansas %>%
filter(state=="Kansas") %>%
select(year_qtr, lngdpcapita) %>%
mutate(ys=predict(syn)) %>%
rename(y=lngdpcapita) %>%
mutate(gap=y-ys)
dp
dp
dp %>%
ggplot()+
geom_line(aes(y=y,x=year_qtr)) +
geom_line(aes(y=ys,x=year_qtr), linetype = "dashed")+
ylab("Per capita GDP")+
xlab("year/qtr")+
geom_vline(xintercept=2012.50, color = "black", size=1, linetype="dashed")
?augsynth
write('PATH="${RTOOLS40_HOME}\\usr\\bin;${PATH}"', file = "~/.Renviron", append = TRUE)
Sys.which("make")
install.packages("jsonlite", type = "source")
??jsonlite
blogdown:::preview_site()
blogdown:::preview_site()
blogdown:::preview_site()
install.packages('tinytex')
blogdown:::preview_site()
install.packages('kableExtra')
install.packages('kable')
install.packages('knitr')
install.packages("knitr")
install.packages('bookdown')
install.packages('tinytex')
?kbl
??kbl
# Espacio de trabajo ----
rm(list = ls())
options(scipen=999) # Prevenir notación científica
setwd("C:/Users/Irvin/Dropbox/curso_EPS/eps-2022/content/tareas")
setwd("C:/Users/rojas/Dropbox/curso_EPS/eps-2022/content/tareas")
library(tidyverse)
library(janitor)
data.angrist<-read_csv("./STAR_public_use.csv",
locale = locale(encoding = "latin1"))   %>%
clean_names() %>%
filter(noshow==0)
data.angrist<-read_csv("STAR_public_use.csv",
locale = locale(encoding = "latin1"))   %>%
clean_names() %>%
filter(noshow==0)
setwd("C:/Users/rojas/Dropbox/curso_EPS/eps-2022/content/tareas/tarea_1)
library(tidyverse)
library(janitor)
data.angrist<-read_csv("STAR_public_use.csv",
setwd("C:/Users/rojas/Dropbox/curso_EPS/eps-2022/content/tareas/tarea_1")
library(tidyverse)
library(janitor)
data.angrist<-read_csv("STAR_public_use.csv",
locale = locale(encoding = "latin1"))   %>%
clean_names() %>%
filter(noshow==0)
data.angrist <- data.angrist %>%
mutate(gpa_year1=ifelse(is.na(grade_20059_fall),NA,gpa_year1),
grade_20059_fall=ifelse(is.na(gpa_year1),NA,grade_20059_fall))
summary(lm(gpa_year1 ~ ssp + sfp+ sfsp+
factor(sex)+
factor(mtongue)+ factor(hsgroup)+factor(numcourses_nov1)+
factor(lastmin)+
factor(mom_edn)+
factor(dad_edn),
data=data.angrist))$coef[1:4,]
data.efect <- data.angrist %>%
filter(gpa_year1 != "NA" & grade_20059_fall != "NA") %>%
filter(noshow == 0)%>%
select(noshow,age,ssp,sfp,sfsp,gpa_year1,grade_20059_fall,noshow,sex,
mtongue,hsgroup,numcourses_nov1,lastmin,mom_edn,dad_edn)
summary(lm(gpa_year1 ~ ssp + sfp+ sfsp+
factor(sex)+
factor(mtongue)+ factor(hsgroup)+factor(numcourses_nov1)+
factor(lastmin)+
factor(mom_edn)+
factor(dad_edn),
data=data.efect))$coef[1:4,]
# Espacio de trabajo ----
rm(list = ls())
options(scipen=999) # Prevenir notación científica
setwd("C:/Users/rojas/Dropbox/curso_EPS/eps-2022/content/tareas/tarea_1")
library(tidyverse)
library(janitor)
data.angrist<-read_csv("STAR_public_use.csv",
locale = locale(encoding = "latin1"))   %>%
clean_names() %>%
filter(noshow==0)
data.efect <- data.angrist %>%
filter(gpa_year1 != "NA" & grade_20059_fall != "NA") %>%
filter(noshow == 0)%>%
select(noshow,age,ssp,sfp,sfsp,gpa_year1,grade_20059_fall,noshow,sex,
mtongue,hsgroup,numcourses_nov1,lastmin,mom_edn,dad_edn)
summary(lm(gpa_year1 ~ ssp + sfp+ sfsp+
factor(sex)+
factor(mtongue)+ factor(hsgroup)+factor(numcourses_nov1)+
factor(lastmin)+
factor(mom_edn)+
factor(dad_edn),
data=data.efect))$coef[1:4,]
data.angrist<-read_csv("STAR_public_use (2).csv",
locale = locale(encoding = "latin1"))   %>%
clean_names() %>%
filter(noshow==0)
data.efect <- data.angrist %>%
filter(gpa_year1 != "NA" & grade_20059_fall != "NA") %>%
filter(noshow == 0)%>%
select(noshow,age,ssp,sfp,sfsp,gpa_year1,grade_20059_fall,noshow,sex,
mtongue,hsgroup,numcourses_nov1,lastmin,mom_edn,dad_edn)
summary(lm(gpa_year1 ~ ssp + sfp+ sfsp+
factor(sex)+
factor(mtongue)+ factor(hsgroup)+factor(numcourses_nov1)+
factor(lastmin)+
factor(mom_edn)+
factor(dad_edn),
data=data.efect))$coef[1:4,]
dato <- data.angrist %>%
filter(noshow==0) %>%
drop_na(grade_20059_fall) %>%
drop_na(gpa_year1) %>%
drop_na(lastmin)# se eliminaron los NA de los controles para que la muestra pudiera correrse
#modelar las variables de interés
modl <-lm(as.numeric(gpa_year1) ~ factor(ssp) + factor(sfp) + factor(sfsp),
data= dato)
summary(modl)
#modelar las variables de interés
modl <-lm(as.numeric(gpa_year1) ~ factor(ssp) + factor(sfp) + factor(sfsp) +
factor(sex)+
factor(mtongue)+ factor(hsgroup)+factor(numcourses_nov1)+
factor(lastmin)+
factor(mom_edn)+
factor(dad_edn),
data= dato)
summary(modl)
data.angrist<-read_csv("STAR_public_use (2).csv",
locale = locale(encoding = "latin1"))   %>%
clean_names() %>%
filter(noshow==0)
##nuevo intento
dato <- data.angrist %>%
filter(noshow==0) %>%
drop_na(grade_20059_fall) %>%
drop_na(gpa_year1)
#modelar las variables de interés
modl <-lm(as.numeric(gpa_year1) ~ factor(ssp) + factor(sfp) + factor(sfsp) +
factor(sex)+
factor(mtongue)+ factor(hsgroup)+factor(numcourses_nov1)+
factor(lastmin)+
factor(mom_edn)+
factor(dad_edn),
data= dato)
summary(modl)
summary(modl)$coef[1:4,]
data.angrist<-read_csv("STAR_public_use (2).csv",
locale = locale(encoding = "latin1"))   %>%
clean_names()
##nuevo intento
dato <- data.angrist %>%
filter(noshow==0) %>%
drop_na(grade_20059_fall) %>%
drop_na(gpa_year1)
#modelar las variables de interés
modl <-lm(as.numeric(gpa_year1) ~ factor(ssp) + factor(sfp) + factor(sfsp) +
factor(sex)+
factor(mtongue)+ factor(hsgroup)+factor(numcourses_nov1)+
factor(lastmin)+
factor(mom_edn)+
factor(dad_edn),
data= dato)
summary(modl)$coef[1:4,]
data.angrist<-read_csv("STAR_public_use (2).csv",
locale = locale(encoding = "latin1"))   %>%
clean_names()
##nuevo intento
dato <- data.angrist %>%
filter(noshow==0) %>%
drop_na(grade_20059_fall) %>%
drop_na(gpa_year1) %>%
drop_na(lastmin)# se eliminaron los NA de los controles para que la muestra pudiera correrse
#modelar las variables de interés
modl <-lm(as.numeric(gpa_year1) ~ factor(ssp) + factor(sfp) + factor(sfsp) +
factor(sex)+
factor(mtongue)+ factor(hsgroup)+factor(numcourses_nov1)+
factor(lastmin)+
factor(mom_edn)+
factor(dad_edn),
data= dato)
summary(modl)$coef[1:4,]
data.angrist<-read_csv("STAR_public_use.csv",
locale = locale(encoding = "latin1"))   %>%
clean_names()
##nuevo intento
dato <- data.angrist %>%
filter(noshow==0) %>%
drop_na(grade_20059_fall) %>%
drop_na(gpa_year1) %>%
drop_na(lastmin)# se eliminaron los NA de los controles para que la muestra pudiera correrse
#modelar las variables de interés
modl <-lm(as.numeric(gpa_year1) ~ factor(ssp) + factor(sfp) + factor(sfsp) +
factor(sex)+
factor(mtongue)+ factor(hsgroup)+factor(numcourses_nov1)+
factor(lastmin)+
factor(mom_edn)+
factor(dad_edn),
data= dato)
summary(modl)$coef[1:4,]
summary(modl)$N
summary(modl)$n
nobs(modl)
